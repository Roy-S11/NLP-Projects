{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category=df.Category.map({'ham':0, 'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam = df[df.Category==1]\n",
    "df_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham = df[df.Category==0].sample(1000)\n",
    "df_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "0    1000\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.concat([df_spam, df_ham])\n",
    "df_new.Category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_Test Spilit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train,y_test = train_test_split(df_new.Message, df_new.Category, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "0    789\n",
       "1    608\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "0    211\n",
       "1    139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 2017, 2663, 1002, 6694, 8889,  102,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [ 101, 2204, 2851,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([1., 0.]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenizer_fun(texts, labels):\n",
    "    encodings = tokenizer(texts, padding = 'max_length', max_length=128, truncation=True, return_tensors='pt')\n",
    "    return encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "tokenizer_fun([\"You win $100000\", \"Good Morning\"], [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:train\n",
      " 3642    You can stop further club tones by replying \"S...\n",
      "2011    Dunno lei... I thk mum lazy to go out... I nev...\n",
      "1155    Did u find a sitter for kaitlyn? I was sick an...\n",
      "19      England v Macedonia - dont miss the goals/team...\n",
      "3208            This phone has the weirdest auto correct.\n",
      "Name: Message, dtype: object\n",
      "\n",
      "X:train\n",
      " 3642    1\n",
      "2011    0\n",
      "1155    0\n",
      "19      1\n",
      "3208    0\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"X:train\\n {x_train.head(5)}\\n\")\n",
    "print(f\"X:train\\n {y_train.head(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You can stop further club tones by replying \"STOP MIX\" See my-tone.com/enjoy. html for terms. Club tones cost GBP4.50/week. MFL, PO Box 1146 MK45 2WT (2/3)',\n",
       " 'Dunno lei... I thk mum lazy to go out... I neva ask her yet...']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DataFrame to list\n",
    "x_train.values.tolist()[:2]# Get the first two rows  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_id, train_attention_mask, train_labels = tokenizer_fun(x_train.values.tolist(), y_train.values.tolist())\n",
    "infer_input_id, infer_attention_mask, infer_labels = tokenizer_fun(x_test.values.tolist(), y_test.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorDataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "# Create TensorDataset\n",
    "train_dataset = TensorDataset(train_input_id, train_attention_mask, train_labels)\n",
    "test_dataset = TensorDataset(infer_input_id, infer_attention_mask, infer_labels)\n",
    "\n",
    "# Wrap with DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "hidden_size = bert.config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Class and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "\n",
    "        for para in self.bert.parameters():\n",
    "            para.requires_grad = False #freeze all BERT layers\n",
    "    \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(bert.config.hidden_size,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input_id, attention_mask):\n",
    "        bert_output = self.bert(input_ids = input_id, attention_mask = attention_mask)\n",
    "        sentence_embedding = bert_output.last_hidden_state[:,0,:]\n",
    "        return self.classifier(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Epoch: 0, Loss:  0.69\n",
      "Batch: 1, Epoch: 0, Loss:  0.65\n",
      "Batch: 2, Epoch: 0, Loss:  0.58\n",
      "Batch: 3, Epoch: 0, Loss:  0.52\n",
      "Batch: 4, Epoch: 0, Loss:  0.48\n",
      "Batch: 5, Epoch: 0, Loss:  0.45\n",
      "Batch: 6, Epoch: 0, Loss:  0.38\n",
      "Batch: 7, Epoch: 0, Loss:  0.36\n",
      "Batch: 8, Epoch: 0, Loss:  0.36\n",
      "Batch: 9, Epoch: 0, Loss:  0.31\n",
      "Batch: 10, Epoch: 0, Loss:  0.28\n",
      "Batch: 11, Epoch: 0, Loss:  0.33\n",
      "Batch: 12, Epoch: 0, Loss:  0.22\n",
      "Batch: 13, Epoch: 0, Loss:  0.23\n",
      "Batch: 14, Epoch: 0, Loss:  0.24\n",
      "Batch: 15, Epoch: 0, Loss:  0.14\n",
      "Batch: 16, Epoch: 0, Loss:  0.18\n",
      "Batch: 17, Epoch: 0, Loss:  0.16\n",
      "Batch: 18, Epoch: 0, Loss:  0.14\n",
      "Batch: 19, Epoch: 0, Loss:  0.18\n",
      "Batch: 20, Epoch: 0, Loss:  0.12\n",
      "Batch: 21, Epoch: 0, Loss:  0.11\n",
      "Epoch 1/3, Training Loss: 0.3229006454348564\n",
      "Batch: 0, Epoch: 1, Loss:  0.09\n",
      "Batch: 1, Epoch: 1, Loss:  0.06\n",
      "Batch: 2, Epoch: 1, Loss:  0.13\n",
      "Batch: 3, Epoch: 1, Loss:  0.08\n",
      "Batch: 4, Epoch: 1, Loss:  0.15\n",
      "Batch: 5, Epoch: 1, Loss:  0.11\n",
      "Batch: 6, Epoch: 1, Loss:  0.11\n",
      "Batch: 7, Epoch: 1, Loss:  0.07\n",
      "Batch: 8, Epoch: 1, Loss:  0.07\n",
      "Batch: 9, Epoch: 1, Loss:  0.04\n",
      "Batch: 10, Epoch: 1, Loss:  0.08\n",
      "Batch: 11, Epoch: 1, Loss:  0.08\n",
      "Batch: 12, Epoch: 1, Loss:  0.11\n",
      "Batch: 13, Epoch: 1, Loss:  0.08\n",
      "Batch: 14, Epoch: 1, Loss:  0.06\n",
      "Batch: 15, Epoch: 1, Loss:  0.12\n",
      "Batch: 16, Epoch: 1, Loss:  0.08\n",
      "Batch: 17, Epoch: 1, Loss:  0.12\n",
      "Batch: 18, Epoch: 1, Loss:  0.16\n",
      "Batch: 19, Epoch: 1, Loss:  0.22\n",
      "Batch: 20, Epoch: 1, Loss:  0.06\n",
      "Batch: 21, Epoch: 1, Loss:  0.07\n",
      "Epoch 2/3, Training Loss: 0.09790993718938394\n",
      "Batch: 0, Epoch: 2, Loss:  0.11\n",
      "Batch: 1, Epoch: 2, Loss:  0.09\n",
      "Batch: 2, Epoch: 2, Loss:  0.09\n",
      "Batch: 3, Epoch: 2, Loss:  0.15\n",
      "Batch: 4, Epoch: 2, Loss:  0.13\n",
      "Batch: 5, Epoch: 2, Loss:  0.11\n",
      "Batch: 6, Epoch: 2, Loss:  0.06\n",
      "Batch: 7, Epoch: 2, Loss:  0.04\n",
      "Batch: 8, Epoch: 2, Loss:  0.06\n",
      "Batch: 9, Epoch: 2, Loss:  0.06\n",
      "Batch: 10, Epoch: 2, Loss:  0.05\n",
      "Batch: 11, Epoch: 2, Loss:  0.05\n",
      "Batch: 12, Epoch: 2, Loss:  0.04\n",
      "Batch: 13, Epoch: 2, Loss:  0.05\n",
      "Batch: 14, Epoch: 2, Loss:  0.05\n",
      "Batch: 15, Epoch: 2, Loss:  0.09\n",
      "Batch: 16, Epoch: 2, Loss:  0.02\n",
      "Batch: 17, Epoch: 2, Loss:  0.09\n",
      "Batch: 18, Epoch: 2, Loss:  0.02\n",
      "Batch: 19, Epoch: 2, Loss:  0.10\n",
      "Batch: 20, Epoch: 2, Loss:  0.15\n",
      "Batch: 21, Epoch: 2, Loss:  0.02\n",
      "Epoch 3/3, Training Loss: 0.07540276528082111\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "# Traning Loops\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch, (input_ids, attention_mask,lables) in enumerate(train_loader):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        lables = lables.to(device, dtype = torch.float)\n",
    "                \n",
    "\n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask).squeeze()\n",
    "        loss= criterion(outputs, lables)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Batch: {batch}, Epoch: {epoch}, Loss:  {loss.item():0.2f}\")\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.07798121310770512, Validation accuracy: 0.971429\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "total_val_loss = 0\n",
    "correct_prediction = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels in test_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask).squeeze()\n",
    "        loss= criterion(outputs, labels.view_as(outputs)) \n",
    "        total_val_loss+=loss.item()\n",
    "\n",
    "        preds = (outputs > 0.5).float()\n",
    "        correct_prediction += torch.sum(preds == labels) \n",
    "\n",
    "avg_test_loss = total_val_loss / len(test_loader)\n",
    "val_accuracy = correct_prediction.double() / len(test_dataset) \n",
    "print(f\"Validation loss: {avg_test_loss}, Validation accuracy: {val_accuracy:4f}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Real World Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, text, max_length=128):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Tokenize input text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask).squeeze()\n",
    "        prediction = (output > 0.5).float().item()\n",
    "        return 'spam' if prediction == 1 else 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \" you win a lottery! click here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \" We will meet for a talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \" congratulation! you got cash prize  of $1000000000 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \" You want to make new frined, click our websites \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(model, \" If you want to come upstaires you have to click lift button \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
